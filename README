NAME
    Text::SemanticDiff - Creates Semantic Diffs of Text files.

SYNOPSIS
      use Text::SemanticDiff;

      my @diff = sdiff(/@old, /@new);

DESCRIPTION
    Standard diffs have the problem of being line-oriented. While this works
    well for code, it doesn't work as well in natural language files. This
    module attempts to do a slightly better job: It first compares in the
    normal line-oriented fashion, then compares inside the line on semantic
    elements: subclauses and phrases, delineated by punctuation. The most
    basic semantic element would be a sentence. (Ending with a period.)

    The interface and output format is similar to Algorithm::Diff, to the
    point that on a purely line-oriented file (where there is only one
    semantic element per line) it should be identical.

USAGE
    semantic_diff( \@, \@, $ )
    sdiff( \@, \@, $ )
        `sdiff()' is just a wrapper around `semantic_diff()' - it's
        convenient to have the shorter name.

        The main comparison function: It takes two or three arguments. The
        first two must be references to the lists of items to be compared.
        The optional third is a regular expression string to be used to
        separate semantic elements. (The default is to use the `\p{Punct}'
        character class. See perlrecharclass for details.)

        Returns a list with the smallest set of changes needed to convert
        the first list into the second. The list is a set of hunks: Each
        hunk is a set of contiguous lines that need to be added, deleted, or
        replaced. Each line in the hunk may have contain it's own list of
        hunks that were separated semantically.

        It's probably easier to give an example. The following two lists:

            ( 'a', 'b', 'c', 'Hello, there, Dick', 'd' )
            ( 'a', 'e', 'c', 'Hi, there, Jane', 'd' )

        Produce the following output:

            (
              [ [ '-', 1, 'b' ], [ '+', 1, 'e' ] ],
              [ [ '!', 3,
                    [
                    [ [ '-', 0, 'Hello,' ],  [ '+', 0, 'Hi,' ], ],
                    [ [ '-', 2, ' Dick' ], [ '+', 2, ' Jane' ] ]
                    ]
                ] ]
            )

        The first hunk is the second item the the lists (array position
        '1'). We remove the initial value 'b' (-) and replace (+) it with
        'e'.

        The second hunk is the fourth item in the lists; it has been broken
        down into subelements (!). (Poorly: The grammar is atrocious...) Of
        those subelements, we have two hunks: The first first subelement of
        the phrase, where we delete 'Hello,' and replace it with 'Hi,'. The
        second hunk is the third subelement of the phrase, where we replace
        ' Dick' with ' Jane'. (Note that whitespace is conserved, and
        considered part of the *following* hunk.)

        `sdiff()' is exported by default. The other functions are not.

    separator()
        Returns the default separator regular expression used to sperate
        semantic chunks. As noted above that's currently `\p{Punct}', but if
        you need it in your code it is best to get it here, in case that
        needs to change in the future.

BUGS
    I haven't checked every edge case yet: This module attempts to prefer
    adding and replacing whole lines to breaking the lines up when
    applicable, but there may be cases where it doesn't.

    I'm not sure how well `wantarray' propagates through callers. This
    should return a reference to the list when called in scalar context, but
    again it hasn't been fully tested.

HISTORY
    0.01 Thu Apr 3 16:58:12 2014 - original version; created by
    ExtUtils::ModuleMaker 0.51

AUTHOR
        Daniel T. Staal
        CPAN ID: DStaal
        DStaal@usa.net

COPYRIGHT
    This program is free software; you can redistribute it and/or modify it
    under the same terms as Perl itself.

    The full text of the license can be found in the LICENSE file included
    with this module.

SEE ALSO
    Algorithm::Diff

    This module was partially inspired by an article by Brandon Rhodes on
    Semantic Linefeeds:
    http://rhodesmill.org/brandon/2012/one-sentence-per-line/

